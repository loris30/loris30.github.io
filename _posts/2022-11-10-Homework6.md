---
layout: post
title: Homework 6
subtitle: T13, T14, A10
cover-img: /assets/img/statistics_icon.jpg
thumbnail-img: /assets/img/statistics_icon.jpg
share-img: /assets/img/statistics_icon.jpg
tags: [books, test]
---

### T13: 
Before understanding the concept of probability, we defined, in the previous lecture, the concept of relative frequency of a value of a certain attribute. We defined the univariate distribution and the multivariate distribution and we also defined the concept of marginal and conditional relative frequency. We started with a statistical units, then we performed a survay on the statistical units, we stored in a table some attributes to create a certain distribution and then with this value we can perform the absolute frequency of a certain characteristics, the relative frequency of a certain characteristics and so on. About of the conditional frequency, we can also explain this concept in an abstract way:

![](/assets/img/Homework4_T7.png)

Thanks to this concept, we can intuitively described and uses some properties of the relative frequency:

The relative frequency is included between 0 and 1 and this frequency is not negative
0 ≤ freq(A) ≤ 1

If A and B are disjoint event then:
freq(A ∩ B) = freq(A) + freq (B)

Disjoint event = two event A and B are incompatible. So we cannot have both events.

This aspect is like the area. if we have two surfaces s1 and s2. And this two surfaces are disjoint then:

stot = s1 + s2

if s1 and s2 are not disjoint, we have to consider also the intersection:

stot = s1 + s2 – (s1 ∩ s2)

If set is empty then the relative frequency is 0. For example we have an event that never happen. Instead the relative frequency of the “population” is 1 because we are considering the events that happen for each unit in the statistical units.
f(∅) = 0

f(population) = 1

Before notice an important aspect that links these properties to the probability, we talk about of three definition of probability:

Classical approach: The probability of an event is the ratio between the number of favorable cases and the number of possible cases. Here we know apriori the possible cases and the favorable cases. If an experiment has n simple outcomes, this method assign a probability of 1/n to each outcome. In other words, each outcome is assumed to have an equal probabiliy of occurence.
Relative-frequency approach: The probability of an event is associated with the relative frequency of the occurrence of the event itself, on a large number of tests tending to infinity. So given a repeatable experiment and a set of events that are all the possible outcomes of that experiment, we can measure the frequency of the various events after a certain number of repetitions. Suppose that A is an event and assume that you have performed the same experiment n times, so n is the number of times A could have occurred. nA is the number of times that A did occur. And nA/n is the relative frequency. Then we can define P(A) as: P(A) = limn->∞ (nA/n). This definition is a possible explanation of the parallelism between the properties of the relative frequency and the axioms for probability measure. This definition has several problems: it is used only for repeatable experiments and we have n->∞, but we cannot never reach the ∞. This definition links probability to frequency. Then we can conclude that, if probability is a frequency, that it must have all the properties that also frequency has.
Subjective approach: The probability of an event is provided according to personal experience and available information. it is the degree of belief that we hold in the occurrence of an event.
This three definition have problem to define probability. We can notice that the properties of frequency are almost identical to the three axioms of probability. Kolmogorov realize that we cannot perfectly define the probability and he realize that the properties of the measure theory could also be applied to probability. For this reason in the 1933 Kolmogorov define the probability P as measure on the measure unit (Ω, F, P). And he defined the probability axioms:

The probability of an event is a non-negative real number: P(E)∈R, P(E) ≥ 0 ∀E∈F. Where F is the event space.  
The maximum possible probability is the probability of the whole set that is 1: P(Ω)=1. Notice that this is the only case where the property of probability is in contrast with the property of the measure theory.
The probability of the union of two disjoint events is the sum of the probability of those events:

![](/assets/img/Homework4_T7.2.png)

### T14: 
In mathematics, probabilistic metric spaces are a generalization of metric spaces where the distance no longer takes values in the non-negative real numbers R ≥ 0, but in distribution functions.

Let D+ be the set of all probability distribution functions F such that F(0) = 0 (F is a nondecreasing, left continuous mapping from R into [0, 1] such that max(F) = 1).

Then given a non-empty set S and a function F: S × S → D+ where we denote F(p, q) by Fp,q for every (p, q) ∈ S × S, the ordered pair (S, F) is said to be a probabilistic metric space if:

For all u and v in S, u = v if and only if Fu,v(x) = 1 for all x > 0.
For all u and v in S, Fu,v = Fv,u.
For all u, v and w in S, Fu,v(x) = 1 and Fv,w(y) = 1 ⇒ Fu,w(x + y) = 1 for x, y > 0.
A metric space is said to be complete if every sequence of points in which the terms are eventually pairwise arbitrarily close to each other (a so-called Cauchy sequence) converges to a point in the metric space. The usual metric on the rational numbers is not complete since some Cauchy sequences of rational numbers do not converge to rational numbers. For example, the rational number sequence 3, 3.1, 3.14, 3.141, 3.1415, 3.14159, … converges to π, which is not a rational number. However, the usual metric on the real numbers is complete, and, moreover, every real number is the limit of a Cauchy sequence of rational numbers. In this sense, the real numbers form the completion of the rational numbers. The proof of this fact, given in 1914 by the German mathematician Felix Hausdorff, can be generalized to demonstrate that every metric space has such a completion.




### T9: 
Statistics in Cybersecurity:
Measure theory is the study of measures. It generalizes the intuitive notions of length, area, and volume. The earliest and most important examples are Jordan measure and Lebesgue measure.

It originated in the real analysis and is used now in many areas of mathematics like, for instance, geometry, probability theory, dynamical systems, functional analysis, etc.

Given a measure m, one can define the integral of suitable real valued functions with respect to m. Riemann integral is applied to continuous functions or functions with “few“ points of discontinuity. For measurable functions that can be discontinuous “almost everywhere” Riemann integral does not make sense. However it is possible to define more flexible and powerful Lebesgue’s integral (integral with respect to Lebesgue’s measure) which is one of the key notions of modern analysis.

References: 

[https://datapeaker.com/en/big–data/axioms-of-probability-three-axioms-of-probability/](https://datapeaker.com/en/big–data/axioms-of-probability-three-axioms-of-probability/)
[https://en.wikipedia.org/wiki/Probability_axioms](https://en.wikipedia.org/wiki/Probability_axioms)
[https://sshivam-singh96.medium.com/difference-between-relative-frequency-probability-b0152600251](https://sshivam-singh96.medium.com/difference-between-relative-frequency-probability-b0152600251)
[https://en.wikipedia.org/wiki/Probability_space](https://en.wikipedia.org/wiki/Probability_space)
[https://en.wikipedia.org/wiki/Probabilistic_metric_space](https://en.wikipedia.org/wiki/Probabilistic_metric_space)
[https://www.britannica.com/science/metric-space](https://www.britannica.com/science/metric-space)
[https://en.wikipedia.org/wiki/Probability_theory](https://en.wikipedia.org/wiki/Probability_theory)
[https://warwick.ac.uk/fac/sci/maths/currentstudents/ughandbook/year3/ma359/](https://warwick.ac.uk/fac/sci/maths/currentstudents/ughandbook/year3/ma359/)


### A10: 
The proposed solution is in the ZIP file that can be found at [this GitHub link](https://github.com/loris30/StatisticsHomework/).

![](assets/GIF/Homework4.GIF.gif)


